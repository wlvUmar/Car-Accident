{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3039610,"sourceType":"datasetVersion","datasetId":1861670}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:27.677196Z","iopub.execute_input":"2025-07-05T08:01:27.677405Z","iopub.status.idle":"2025-07-05T08:01:27.698354Z","shell.execute_reply.started":"2025-07-05T08:01:27.677382Z","shell.execute_reply":"2025-07-05T08:01:27.697669Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/analysis-of-us-accidents/US_Accidents_May19_Migrated Data.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/analysis-of-us-accidents/US_Accidents_May19_Migrated Data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:27.698976Z","iopub.execute_input":"2025-07-05T08:01:27.699221Z","iopub.status.idle":"2025-07-05T08:01:47.980068Z","shell.execute_reply.started":"2025-07-05T08:01:27.699205Z","shell.execute_reply":"2025-07-05T08:01:47.979518Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"columns_to_drop = [\n    'ID', \n    'Number', \n    'Airport_Code',\n    'End_Lat',\n    'End_Time',\n    'End_Lng', \n    'Description', \n    'Source', \n    'Timezone',\n    'Country',\n    \"County\", \n    'Records', \n    'Number of Records', \n    'Astronomical_Twilight',\n    'Nautical_Twilight',\n    'Civil_Twilight',\n    'Zipcode',  \n    'Turning_Loop',\n    'count of Bump', \n    'count Traffic Signal', \n    'count of county', \n    'Count of Crossing',\n    'Count of accidents',\n    'Wind_Chill(F)', \n    'Weather_Timestamp', \n    \"TMC\", \n    \"Street\", \n    'Distance(mi)',\n    'Precipitation(in)', \n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:47.980887Z","iopub.execute_input":"2025-07-05T08:01:47.981147Z","iopub.status.idle":"2025-07-05T08:01:47.985550Z","shell.execute_reply.started":"2025-07-05T08:01:47.981124Z","shell.execute_reply":"2025-07-05T08:01:47.984873Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df = df.drop(columns=columns_to_drop)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:47.986286Z","iopub.execute_input":"2025-07-05T08:01:47.986555Z","iopub.status.idle":"2025-07-05T08:01:48.464218Z","shell.execute_reply.started":"2025-07-05T08:01:47.986532Z","shell.execute_reply":"2025-07-05T08:01:48.463672Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:48.464991Z","iopub.execute_input":"2025-07-05T08:01:48.465240Z","iopub.status.idle":"2025-07-05T08:01:48.470120Z","shell.execute_reply.started":"2025-07-05T08:01:48.465217Z","shell.execute_reply":"2025-07-05T08:01:48.469592Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Index(['Amenity', 'Bump', 'Calculation1', 'City', 'Crossing', 'Give_Way',\n       'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Severity', 'Side',\n       'Start_Time', 'State', 'Station', 'Stop', 'Sunrise_Sunset',\n       'Temperature(F)', 'Traffic_Calming', 'Traffic_Signal', 'Visibility(mi)',\n       'Weather_Condition', 'Wind_Direction', 'Humidity(%)', 'Pressure(in)',\n       'Start_Lat', 'Start_Lng', 'Wind_Speed(mph)'],\n      dtype='object')"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import joblib\nimport xgboost as xgb\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler,PowerTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\n\nclass CustomLabelEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.encoders = {}\n\n    def fit(self, X, y=None):\n        for col in X.columns:\n            le = LabelEncoder()\n            le.fit(X[col].astype(str))\n            self.encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n        for col in X.columns:\n            mapping = self.encoders[col]\n            X_transformed[col] = X_transformed[col].astype(str).map(mapping).fillna(0).astype(int)\n\n        return X_transformed\n\n        \nclass GeographicEncoder(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        X[\"Lat_sin\"] = np.sin(np.radians(X[\"Start_Lat\"]))\n        X[\"Lat_cos\"] = np.cos(np.radians(X[\"Start_Lat\"]))\n        X[\"Lng_sin\"] = np.sin(np.radians(X[\"Start_Lng\"]))\n        X[\"Lng_cos\"] = np.cos(np.radians(X[\"Start_Lng\"]))\n\n        return X.drop(columns=[\"Start_Lat\", \"Start_Lng\"])\n\n\n\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        X['Start_Time'] = pd.to_datetime(X['Start_Time'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n\n        X['Hour'] = X['Start_Time'].dt.hour\n        X['DayOfWeek'] = X['Start_Time'].dt.dayofweek\n        X['IsWeekend'] = X['DayOfWeek'] >= 5\n\n        X['IsNight'] = (X['Sunrise_Sunset'] == 'Night').astype(int)\n        X['IsRainy'] = X['Weather_Condition'].str.contains('Rain|Storm', na=False).astype(int)\n        X['IsFoggy'] = X['Weather_Condition'].str.contains('Fog|Haze', na=False).astype(int)\n\n        X['HasObstacle'] = X[['Amenity', 'Bump', 'Traffic_Calming', 'Crossing', \n                              'Junction', 'Stop', 'Traffic_Signal']].sum(axis=1) > 0\n        X['HasObstacle'] = X['HasObstacle'].astype(int)\n\n        X.drop(columns=[\n            'Start_Time', 'DayOfWeek',\n            'Sunrise_Sunset', 'Weather_Condition',\n            'Amenity', 'Bump', 'Traffic_Calming', 'Crossing',\n            'Junction', 'Stop', 'Traffic_Signal'\n        ], inplace=True, errors='ignore')\n        \n        return X\n\nclass DataCleaner(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n\n        missing_values = X.isna().sum()\n        missing_values_to_drop = missing_values[missing_values < 9000].index\n        X = X.dropna(subset=missing_values_to_drop)\n\n        weather_cols = [\"Temperature(F)\", \"Visibility(mi)\", \"Pressure(in)\", \"Wind_Speed(mph)\", \"Humidity(%)\"]\n        X[weather_cols] = X[weather_cols].fillna(X[weather_cols].median())\n\n        categorical_columns = [\"Weather_Condition\", \"Wind_Direction\"]\n        for col in categorical_columns:\n            X[col] = X[col].fillna(X[col].mode()[0])\n\n        X = X.drop_duplicates()\n\n        boolean_columns = X.select_dtypes(include=[bool]).columns\n        X[boolean_columns] = X[boolean_columns].astype(int)\n\n        \n        X.reset_index(drop=True, inplace=True)\n        return X\n        \ndef create_preprocessing_pipeline():\n    categorical_columns = ['Calculation1', 'City', 'Side', 'State', 'Wind_Direction']\n    numeric_standard = ['Temperature(F)']\n    numeric_minmax = ['Humidity(%)']\n    numeric_power = ['Wind_Speed(mph)', 'Pressure(in)', 'Visibility(mi)']\n    \n    preprocessor = ColumnTransformer([\n        ('categorical', CustomLabelEncoder(), categorical_columns),\n        ('numeric_standard', StandardScaler(), numeric_standard),\n        ('numeric_minmax', MinMaxScaler(), numeric_minmax),\n        ('numeric_power', PowerTransformer(), numeric_power),\n    ], remainder='passthrough')\n\n    pipeline = Pipeline([\n        ('feature_engineering', FeatureEngineer()),\n        ('geographic_encoder', GeographicEncoder()),\n        ('preprocessor', preprocessor),\n    ])\n\n    return pipeline\n\n\ndef create_full_model_pipeline():\n    xgb_classifier = xgb.XGBClassifier(\n        tree_method='hist',\n        device='cuda',\n        objective='multi:softprob',\n        random_state=2,\n        eval_metric='mlogloss',\n        verbosity=1,\n        max_bin=256,\n        learning_rate=0.03,\n        max_depth=12,\n        n_estimators=1000,\n        subsample=0.8\n    )\n\n    full_pipeline = Pipeline([\n        ('cleaning', DataCleaner()),\n        ('features', create_preprocessing_pipeline()),\n        ('classifier', xgb_classifier)\n    ])\n\n    return full_pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:48.470779Z","iopub.execute_input":"2025-07-05T08:01:48.470979Z","iopub.status.idle":"2025-07-05T08:01:48.489840Z","shell.execute_reply.started":"2025-07-05T08:01:48.470956Z","shell.execute_reply":"2025-07-05T08:01:48.489123Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df_filtered = df[df[\"Severity\"].isin([2, 3, 4])].copy()\ndf_filtered[\"Severity\"] = df_filtered[\"Severity\"].map({2: 0, 3: 1, 4: 2})\n\nclasses = np.unique(df_filtered[\"Severity\"])\nweights = compute_class_weight('balanced', classes=classes, y=df_filtered[\"Severity\"])\n\nX_raw = df_filtered.drop(columns=[\"Severity\"]).reset_index(drop=True)\ny_raw = df_filtered[\"Severity\"].reset_index(drop=True)\n\npipeline = create_full_model_pipeline()\n\nX_transformed = pipeline[:-1].fit_transform(X_raw, y_raw)\n\ny_transformed = y_raw.iloc[:len(X_transformed)]\nclasses = np.unique(y_transformed)\nweights = compute_class_weight('balanced', classes=classes, y=y_transformed)\nweight_map = dict(zip(classes, weights))\nsample_weight = y_transformed.map(weight_map)\n\npipeline.named_steps[\"classifier\"].fit(X_transformed, y_transformed, sample_weight=sample_weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:01:48.490535Z","iopub.execute_input":"2025-07-05T08:01:48.490795Z","iopub.status.idle":"2025-07-05T08:04:58.456161Z","shell.execute_reply.started":"2025-07-05T08:01:48.490769Z","shell.execute_reply":"2025-07-05T08:04:58.455388Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.03, max_bin=256, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.03, max_bin=256, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.03, max_bin=256, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import cloudpickle\nINPUT_FEATURES = [\n    'Calculation1', 'City', 'Side', 'State', 'Wind_Direction',\n    'Weather_Condition', 'Sunrise_Sunset', 'Start_Time',\n    'Temperature(F)', 'Visibility(mi)', 'Pressure(in)',\n    'Wind_Speed(mph)', 'Humidity(%)', 'Start_Lat', 'Start_Lng'\n]\npipeline.required_features = INPUT_FEATURES\nwith open(\"xgb_full_pipeline1.pkl\", \"wb\") as f:\n    cloudpickle.dump(pipeline, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:04:58.457046Z","iopub.execute_input":"2025-07-05T08:04:58.457309Z","iopub.status.idle":"2025-07-05T08:05:00.652989Z","shell.execute_reply.started":"2025-07-05T08:04:58.457284Z","shell.execute_reply":"2025-07-05T08:05:00.652187Z"}},"outputs":[],"execution_count":17}]}